{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e85a4ce-6ecf-49f3-ad69-171732c5be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4748\n",
      "475\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "m11_asal = 'model_random_forest_sss_sst_only.pkl'\n",
    "m12_asal = 'model_random_forest.pkl'\n",
    "\n",
    "x_cols_m11 = ['SSS', 'SST']\n",
    "x_cols_m12 = ['LATITUDE', 'SSS', 'SST', 'SSH', 'UO', 'VO', 'MLD']\n",
    "\n",
    "# Compute my testing dates\n",
    "input_data = '../model_collocated_10d_filled' \n",
    "start_date = '20100101'\n",
    "end_date = '20221231'\n",
    "\n",
    "random.seed(56)\n",
    "\n",
    "files = [f for f in os.listdir(input_data) if f.endswith('.feather') and os.path.isfile(os.path.join(input_data, f))]\n",
    "file_names = [os.path.splitext(f)[0] for f in files]\n",
    "file_names = [date for date in file_names if date >= start_date]\n",
    "file_names = [date for date in file_names if date <= end_date]\n",
    "\n",
    "random.shuffle(file_names)\n",
    "split_point = int(len(file_names) * 0.9)  \n",
    "\n",
    "print(len(file_names))\n",
    "testing_dates = file_names[split_point:]\n",
    "\n",
    "testing_dates = [datetime.strptime(date, '%Y%m%d') for date in testing_dates]\n",
    "print(len(testing_dates))\n",
    "# Load my testing dataset\n",
    "test_data = []\n",
    "for date in testing_dates:\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    profiles_data = pd.read_feather(f'{input_data}/{date_str}.feather')\n",
    "    if not profiles_data.empty:\n",
    "        test_data.append(profiles_data) \n",
    "            \n",
    "if test_data:\n",
    "    test_data = pd.concat(test_data, ignore_index=True)  \n",
    "\n",
    "test_data.dropna(inplace=True)\n",
    "test_data = test_data[test_data['LATITUDE'] > -60]\n",
    "test_data = test_data[test_data['LATITUDE'] < 60]\n",
    "\n",
    "r2_m11_as = np.full(46, np.nan)\n",
    "r2_m11_ct = np.full(46, np.nan)\n",
    "ev_m11_as = np.full(46, np.nan)\n",
    "ev_m11_ct = np.full(46, np.nan)\n",
    "mse_m11_as = np.full(46, np.nan)\n",
    "mse_m11_ct = np.full(46, np.nan)\n",
    "mae_m11_as = np.full(46, np.nan)\n",
    "mae_m11_ct = np.full(46, np.nan)\n",
    "\n",
    "r2_m12_as = np.full(46, np.nan)\n",
    "r2_m12_ct = np.full(46, np.nan)\n",
    "ev_m12_as = np.full(46, np.nan)\n",
    "ev_m12_ct = np.full(46, np.nan)\n",
    "mse_m12_as = np.full(46, np.nan)\n",
    "mse_m12_ct = np.full(46, np.nan)\n",
    "mae_m12_as = np.full(46, np.nan)\n",
    "mae_m12_ct = np.full(46, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf35b63-25e5-4427-b65d-b30c46f2f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data.iloc[:,-92:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10747d2a-8a07-461f-aed5-d5ead9ffb6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:   26.9s finished\n"
     ]
    }
   ],
   "source": [
    "# R2, MSE, MAE, EV M11/ASAL, CTEMP\n",
    "model = pickle.load(open(m11_asal, 'rb'))\n",
    "y_pred = model.predict(test_data[x_cols_m11])\n",
    "\n",
    "model2 = pickle.load(open(m12_asal, 'rb'))\n",
    "y_pred2 = model2.predict(test_data[x_cols_m12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365c473b-a99a-4d4a-a88a-d4ff15ac7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,46):\n",
    "    r2_m11_as[i] = r2_score(y_test.iloc[:,i], y_pred[:,i])\n",
    "    ev_m11_as[i] = explained_variance_score(y_test.iloc[:,i], y_pred[:,i])\n",
    "    mse_m11_as[i] = mean_squared_error(y_test.iloc[:,i], y_pred[:,i])\n",
    "    mae_m11_as[i] = mean_absolute_error(y_test.iloc[:,i], y_pred[:,i])\n",
    "\n",
    "    r2_m11_ct[i] = r2_score(y_test.iloc[:,i+46], y_pred[:,i+46])\n",
    "    ev_m11_ct[i] = explained_variance_score(y_test.iloc[:,i+46], y_pred[:,i+46])\n",
    "    mse_m11_ct[i] = mean_squared_error(y_test.iloc[:,i+46], y_pred[:,i+46])\n",
    "    mae_m11_ct[i] = mean_absolute_error(y_test.iloc[:,i+46], y_pred[:,i+46])\n",
    "\n",
    "    r2_m12_as[i] = r2_score(y_test.iloc[:,i], y_pred2[:,i])\n",
    "    ev_m12_as[i] = explained_variance_score(y_test.iloc[:,i], y_pred2[:,i])\n",
    "    mse_m12_as[i] = mean_squared_error(y_test.iloc[:,i], y_pred2[:,i])\n",
    "    mae_m12_as[i] = mean_absolute_error(y_test.iloc[:,i], y_pred2[:,i])\n",
    "\n",
    "    r2_m12_ct[i] = r2_score(y_test.iloc[:,i+46], y_pred2[:,i+46])\n",
    "    ev_m12_ct[i] = explained_variance_score(y_test.iloc[:,i+46], y_pred2[:,i+46])\n",
    "    mse_m12_ct[i] = mean_squared_error(y_test.iloc[:,i+46], y_pred2[:,i+46])\n",
    "    mae_m12_ct[i] = mean_absolute_error(y_test.iloc[:,i+46], y_pred2[:,i+46])\n",
    "# R2, MSE, MAE, EV m12/ASAL, CTEMP\n",
    "del model\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'r2_m11_as': r2_m11_as,\n",
    "    'r2_m11_ct': r2_m11_ct,\n",
    "    'ev_m11_as': ev_m11_as,\n",
    "    'ev_m11_ct': ev_m11_ct,\n",
    "    'mse_m11_as': mse_m11_as,\n",
    "    'mse_m11_ct': mse_m11_ct,\n",
    "    'mae_m11_as': mae_m11_as,\n",
    "    'mae_m11_ct': mae_m11_ct,\n",
    "    'r2_m12_as': r2_m12_as,\n",
    "    'r2_m12_ct': r2_m12_ct,\n",
    "    'ev_m12_as': ev_m12_as,\n",
    "    'ev_m12_ct': ev_m12_ct,\n",
    "    'mse_m12_as': mse_m12_as,\n",
    "    'mse_m12_ct': mse_m12_ct,\n",
    "    'mae_m12_as': mae_m12_as,\n",
    "    'mae_m12_ct': mae_m12_ct,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('random_forest_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34eccc59-a345-4d1b-ba8a-b58ccc1c656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M11 Salinity\n",
      "R2: 0.8841394981738516\n",
      "EV: 0.8841443814723379\n",
      "MSE: 0.08283676285403137\n",
      "MAE: 0.17284012982509322\n",
      "M12 Salinity\n",
      "R2: 0.954922814805305\n",
      "EV: 0.9549859349862251\n",
      "MSE: 0.035482418735213093\n",
      "MAE: 0.10881381150690438\n",
      "M11 Temperature\n",
      "R2: 0.7576362088659839\n",
      "EV: 0.7577023508436771\n",
      "MSE: 5.698026450162697\n",
      "MAE: 1.4975140105776195\n",
      "M12 Temperature\n",
      "R2: 0.8508307399769619\n",
      "EV: 0.8512681045000907\n",
      "MSE: 3.1568424476492347\n",
      "MAE: 0.8567737346456851\n"
     ]
    }
   ],
   "source": [
    "print('M11 Salinity')\n",
    "print(f'R2: {r2_score(y_test.iloc[:,0:46], y_pred[:,0:46])}')\n",
    "print(f'EV: {explained_variance_score(y_test.iloc[:,0:46], y_pred[:,0:46])}')\n",
    "print(f'MSE: {mean_squared_error(y_test.iloc[:,0:46], y_pred[:,0:46])}')\n",
    "print(f'MAE: {mean_absolute_error(y_test.iloc[:,0:46], y_pred[:,0:46])}')\n",
    "\n",
    "print('M12 Salinity')\n",
    "print(f'R2: {r2_score(y_test.iloc[:,0:46], y_pred2[:,0:46])}')\n",
    "print(f'EV: {explained_variance_score(y_test.iloc[:,0:46], y_pred2[:,0:46])}')\n",
    "print(f'MSE: {mean_squared_error(y_test.iloc[:,0:46], y_pred2[:,0:46])}')\n",
    "print(f'MAE: {mean_absolute_error(y_test.iloc[:,0:46], y_pred2[:,0:46])}')\n",
    "\n",
    "print('M11 Temperature')\n",
    "print(f'R2: {r2_score(y_test.iloc[:,46:], y_pred[:,46:])}')\n",
    "print(f'EV: {explained_variance_score(y_test.iloc[:,46:], y_pred[:,46:])}')\n",
    "print(f'MSE: {mean_squared_error(y_test.iloc[:,46:], y_pred[:,46:])}')\n",
    "print(f'MAE: {mean_absolute_error(y_test.iloc[:,46:], y_pred[:,46:])}')\n",
    "\n",
    "print('M12 Temperature')\n",
    "print(f'R2: {r2_score(y_test.iloc[:,46:], y_pred2[:,46:])}')\n",
    "print(f'EV: {explained_variance_score(y_test.iloc[:,46:], y_pred2[:,46:])}')\n",
    "print(f'MSE: {mean_squared_error(y_test.iloc[:,46:], y_pred2[:,46:])}')\n",
    "print(f'MAE: {mean_absolute_error(y_test.iloc[:,46:], y_pred2[:,46:])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c314df-f036-448d-ac29-fcdf6f36485f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
