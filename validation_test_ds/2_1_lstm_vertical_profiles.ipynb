{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a202be6-9275-4bfa-bc4b-4d336a863c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = 6371 * c \n",
    "    return distance\n",
    "\n",
    "def load_data_from_feather(daily_ds):\n",
    "    if isinstance(daily_ds, bytes):\n",
    "        daily_ds = daily_ds.decode('utf-8')    \n",
    "    df = pd.read_feather('model_collocated_10d_filled/'+daily_ds+'.feather')\n",
    "    asal_height_cols = [col for col in df.columns if col.startswith('ASAL_height')]\n",
    "    ctemp_height_cols = [col for col in df.columns if col.startswith('CTEMP_height')]\n",
    "\n",
    "    target_points = [(0, -130), (30, -40), (-50,30), (-35,100)] \n",
    "    \n",
    "    closest_points_df = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    for target_lat, target_lon in target_points:\n",
    "        df['Distance_to_point'] = df.apply(lambda row: haversine(row['LATITUDE'], row['LONGITUDE'], target_lat, target_lon), axis=1)\n",
    "        closest_indices = df[df['Distance_to_point'] == df['Distance_to_point'].min()].index\n",
    "        closest_points_df = pd.concat([closest_points_df, df.loc[closest_indices]], ignore_index=True)\n",
    "    \n",
    "    other_vars = ['LATITUDE', 'LONGITUDE', 'SSS', 'SST', 'SSH', 'MLD', 'UO', 'VO']\n",
    "    \n",
    "    new_df = closest_points_df[other_vars]\n",
    "    \n",
    "    height_dfs = []\n",
    "    for asal_col, ctemp_col in zip(asal_height_cols, ctemp_height_cols):\n",
    "        height_df = new_df.copy()\n",
    "        height_df['HEIGHT'] = asal_col.split('_height')[-1]\n",
    "        height_df['ASAL'] = closest_points_df[asal_col] \n",
    "        height_df['CTEMP'] = closest_points_df[ctemp_col]  \n",
    "        height_dfs.append(height_df)\n",
    "    \n",
    "    final_df = pd.concat(height_dfs, ignore_index=True)\n",
    "    final_df = final_df.dropna()\n",
    "\n",
    "    pivot_table = final_df.pivot_table(index=['LATITUDE', 'LONGITUDE', 'HEIGHT'], values=['SSS', 'SST', 'SSH', 'MLD', 'UO', 'VO', 'ASAL', 'CTEMP'])\n",
    "\n",
    "    filename = os.path.basename(daily_ds)\n",
    "    date_str = filename.split('.')[0]  # Remove the file extension\n",
    "    date = pd.to_datetime(date_str, format='%Y%m%d')\n",
    "    day_of_year = date.dayofyear\n",
    "\n",
    "    pivot_table['DATE'] = day_of_year\n",
    "    pivot_table = pivot_table.reset_index()\n",
    "    pivot_table = pivot_table.astype(float)\n",
    "    pivot_table = pivot_table[['LATITUDE', 'LONGITUDE', 'HEIGHT', 'SSS', 'SST', 'SSH', 'MLD', 'UO', 'VO', 'DATE', 'ASAL', 'CTEMP']]\n",
    "\n",
    "    groups = pivot_table.groupby(['LATITUDE', 'LONGITUDE'])\n",
    "    \n",
    "    arrays = []\n",
    "    \n",
    "    n_row = 46\n",
    "    \n",
    "    with open('min_max_values.json', 'r') as f:\n",
    "        min_max_values = json.load(f)\n",
    "        \n",
    "    for _, group in groups:\n",
    "        if len(group) == n_row:\n",
    "            group_sorted = group.sort_values(by='HEIGHT')\n",
    "            for column in min_max_values['min_values'].keys():\n",
    "                min_value = min_max_values['min_values'][column]\n",
    "                max_value = min_max_values['max_values'][column]\n",
    "                group_sorted[column] = (group_sorted[column] - min_value) / (max_value - min_value)\n",
    "\n",
    "            array = group_sorted.values\n",
    "            if (np.any(array)):\n",
    "                arrays.append(array)\n",
    "    \n",
    "    all_arr = np.stack(arrays)\n",
    "    X = all_arr[:,:,0:10]\n",
    "    y = all_arr[:,:,10:12]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c1913c-6e99-42b7-afc2-e8906961e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_789276/711913512.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  closest_points_df = pd.concat([closest_points_df, df.loc[closest_indices]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 46, 10)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
      "(4, 92)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_data = 'model_collocated_10d_filled/'\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import json \n",
    "\n",
    "model = load_model('model-3.keras')\n",
    "\n",
    "date = '20221029'\n",
    "\n",
    "profiles, _ = load_data_from_feather(date)\n",
    "print(np.shape(profiles))\n",
    "p = model.predict(profiles)\n",
    "p\n",
    "\n",
    "with open('min_max_values.json', 'r') as f:\n",
    "        min_max_values = json.load(f)\n",
    "\n",
    "asal_pred = p[:,:,0] * (min_max_values['max_values']['ASAL'] - min_max_values['min_values']['ASAL']) + min_max_values['min_values']['ASAL']\n",
    "ctemp_pred = p[:,:,1] * (min_max_values['max_values']['CTEMP'] - min_max_values['min_values']['CTEMP']) + min_max_values['min_values']['CTEMP']\n",
    "\n",
    "ds = np.concatenate((asal_pred, ctemp_pred), axis=1)\n",
    "print(np.shape(ds))\n",
    "np.savetxt('model-3_prof.csv', ds, delimiter=\",\", fmt='%f', header=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
